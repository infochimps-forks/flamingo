#!/usr/bin/env ruby
require 'rubygems'
require 'redis-namespace'

$LOAD_PATH.unshift File.expand_path(File.dirname(__FILE__) + '/../lib')
require 'flamingo'
require 'optparse'
require 'wukong'
require 'wukong/store'

#require 'rubygems'
#require 'graphiterb'

# This is a stub definition for the TwitterScrapeJob class which identifies which queue
# to put data on. Later, workers will instantiate this class as it is defined
# by 'wuclan/twitter/scrape_job/twitter_scrape_job'
class TwitterStreamJob
 @queue = "twitter_stream"
end

# Ditto for TwitterStreamPackageJob
class TwitterStreamPackageJob
  @queue = "twitter_stream"
end

module Flamingo
  class Wader
 
    def stop
      if connection
        connection.stop
      end
      flush
      EM.stop
    end

    def package_mutex
      # In general this is not a safe technique - the mutex should be generated by a known
      # thread state - preferably in the inintialization of the object, but in this case
      # the chance of an actual race condition is impossible because a flush event can not
      # be triggered until at least one package_job event has taken place.
      @package_mutex ||= Mutex.new
    end

    def flush

      jobs_to_send = nil

      # The whole point of the timer is to ensure that data that has been placed on the 
      # job_package array gets delivered to resque in a reasonable time. If we are in the
      # flush method, everything on the array is about to be sent, so if there is a timer
      # in effect, its goal will be accomplished by this execution of flush, so we can
      # get rid of it.
      clear_timer 

      # Set up a critical section for emptying the job_package array if it is present. 
      # Not that this section might block the dispacther section of the code, so this
      # section should not do anything time consuming. For this reason, the actual connection 
      # with resque is put off until after the critical section.
      package_mutex.synchronize do
        if @job_package && @job_package.length > 0
          jobs_to_send = @job_package
          @job_package = []
        end
      end
      
      # Hold off on sending the package of to resque until after the critical section.
      # No sense holding up the works while we deal with putting stuff on resque.
      if jobs_to_send
          Resque.enqueue( TwitterStreamPackageJob, jobs_to_send )
      end

    end

    def set_timer
      # If we already have a timer, dont touch it.
      return if @package_timer
      
      # Create a new timer that will flush the job_package in 1 second.
      # Note that flush will take care of cleaning up any timers that have been
      # started.
      @package_timer = EventMachine::Timer.new(1) do 
        flush
      end
    end

    def clear_timer
      # Cancel and delete the package timer if it exists.
      return unless @package_timer
      @package_timer.cancel
      @package_timer = nil
    end


    def package_job job
      # Set up a critical section for adding a job to the queue. This of course
      # might block while the flush method takes care of business. Flush should
      # of course take care to block for the minimum amount of time possible to
      # ensure that the dispatch job is not delayed.
      package_mutex.synchronize do
        @job_package ||= []
        @job_package.push job

        # Check to see if we have a large number of events ready to send
        if @job_package.length > 25

          # Set up a thread from the pool to flush the queue - this way
          # we dont block on reading to send a potentially large chunk of
          # data off to Resque - the reader must not be delayed.
          EM.defer do
            flush
          end

        else
          # Not a lot of data on the package, but make sure that it gets flushed
          # in the near term. Set up a timer to handle the flushing
          set_timer
        end

      end # of critical section

    end

    private
    def dispatch_event event_json
      Flamingo.logger.debug "Wader dispatched event -- monkeypatched"

      #TODO: add graphite performance data back in here. 

      #flamingo_counter.increment("events")
      #flamingo_counter.incrementBy(event_json.length,"bytes")

      # This is the first place where we use the commitlog, so make sure that there is a mutex
      # for it
      @commitlog_mutex ||= Mutex.new

      # Set up a thread from the pool to write to the commitlog - we do not want to block
      # the dispatcher.
      EventMachine.defer do
        @commitlog_mutex.synchronize do
          commitlog << event_json
        end
      end

      package_job( event_json )
    end

    def commitlog
      # If there is a commitlog object already present, all setup is already done
      return @commitlog if @commitlog


      @commitlog = Wukong::Store::ChhChunkedFlatFileStore.new( { :rootdir   => File.expand_path(Flamingo.config.commitlog_path), 
                                                                 :chunktime => Flamingo.config.commitlog_chunk_time , 
                                                                 :filemode  => 'a+'} )

      EventMachine.add_periodic_timer(Flamingo.config.commitlog_chunk_time) do 

        # Note that periodic timer code is actually executed by the reactor thread, so 
        # we want to make sure that the creation of a new chunk file is done by 
        EventMachine.defer do
          # Make sure that someone is not holding a commitlog mutex while we change the log
          # or they may try to write to a file in a bad state
          @commitlog_mutex.synchronize do
            @commitlog.new_chunk 
          end # of critical section
        end # of defered code
      end # of periodic timer code

      @commitlog

    end

  end
end

load File.dirname(__FILE__) + '/flamingod'
